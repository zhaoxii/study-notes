文档
http://redis.cn/commands.html


redis 后台启动
先进行配置文件的配置
然后通过命令：redis-server  /redis.conf



redis-cli 连接上redis




redis16个库，默认使用0号库

redis是单线程+多路IO复用的


redis常用数据类型
字符串string
列表list
集合set
有序集合zset
哈希hash

命令文档：http://redis.cn/commands.html



对key操作的命令：

keys *  查看当前库的所有key
exists key  查询一个key是否存在
type key  查看key是什么类型
del key    删除key  直接删除
unlink  key   根据value选择非阻塞删除(与del类似，但是是异步删除)
expire key time    给key设置过期时间，以秒为单位
ttl key      查看key还有多少秒过期。    -1表示永不过期，-2表示已过期



select 数据库号    切换数据库  (如：select 1)
dbsize  查看当前数据库的key的数量
flushdb  清空当前库
flushall   通杀所有库







-----------------------------------------------------------
字符串string

一个redis字符串的value的最大是512M

字符串常用命令

set key value  重复设置一个key时会覆盖
get key
append key value   在key的原value后面追加
strlen key   获取key的value的长度
setnx  key value  只有在key不存在时，设置key的值
incr key     将key中储存的数字值增1，只能对数字值操作，如果为空，新增值为1
decr  key     将key中储存的数字值减1

incrby  key  步长    将key中储存的数字值增加步长
decrby   key  步长   将key中储存的数字值减去步长


redis中的操作都是原子操作
原子性
所谓原子操作是指不会被线程调度机制打断的操作
这种操作一旦开始，就一直运行至结束，中间不会有任何切换
在单线程中，能够在单条指令中完成的操作都可以认为是原子操作，因为中断只能发生在指令之间
在多线程中，不能被其他进程(线程)打断的操作就是原子操作
redis 单命令的原子性主要得益于redis的单线程



mset key1 value1 key2 value2 ...  设置多个key value
mget  key1 key2 .。。。     获取多个value
msetnx  key1 value1 key2 value2 ...  设置多个key value ，当且仅当所有给定的key都不存在，有一个失败均失败


getrange  key 起始位置  结束位置  获取值的范围，包括起始位置和结束位置
(索引从0开始)
setrange key  起始位置  value   用value覆写key所存储的字符串值，从起始位置开始

setex  key  过期时间 value   设置键值的同时，设置过期时间。秒为单位

getset  key value  以新换旧值，取出旧值，并设置新值



string类型底层存储
类似于java的arraylist








------------------------------------------------------
列表list类型

一键多值
redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部(左边)或尾部(右边)
底层是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差


lpush  key value1 value2 value3....从左边插入一个或多个值
rpush  key value1 value2 value3....从右边插入一个或多个值
lpop   key    从左边取出一个值   值在键在，值光键亡
rpop   key    从右边取出一个值   值在键在，值光键亡

rpoplpush  key1 key2  从key1列表右边取出一个值，插入到key2列表的左边



lrange key  start  stop    按照索引下标获得元素(从左到右)    -1表示右边第一个  0是左边第一个



lindex key  index    按照索引下标获得元素  从左到右

llen key  获得列表长度


linsert  key before/after  value  newvalue  在value的前面/后面插入newvalue


lrem  key n value   从左边删除n个value  从左到右


lset  key index value   将列表key下标为index的值替换为value



List的数据结构是快速链表quickList
首先在元素比较少的时候会使用一块连续的内存存储，这个结果是ziplist，也即压缩列表
他将所有的元素紧挨着一起存储，分配的是一块连续的内存
当数据量比较多时才会改为quickList

redis将链表与ziplist结合起来组成了quicklist。










----------------------------------------
集合set类型

redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set可以自动排重

redis的set是string类型的无序集合，他底层是一个value为null的hash表
所以添加，删除，查找的复杂度都为o(1)



sadd  key value1 value2...   将一个或者多个值加入至key中，如果有重复的则忽略

smembers  key      取出该集合的所有值

sismember  key  value   判断该集合key是否含有该value值，有1，无0

scard  key         返回该集合的元素个数


srem   key value1 value2...  删除集合中的某些元素

spop key     随机从集合中吐出一个值

srandmember   key  n   随机从集合中取出n个值。不会从集合中删除

smove  source destination value  将集合中一个值从一个集合移到另一个集合

sinter  key1  key2    返回两个集合的交集元素

sunion  key1  key2    返回两个集合的并集元素

sdiff   key1 key2      返回两个集合的差集元素(key1中的，不包含key2中的)



set数据结构是dict字典，字典是用哈希表实现的







-------------------------------------------------
哈希hash类型

redis hash是一个键值对的集合

redis hash是一个string类型的field和value的映射表。特别适合用于存储对象


hset  key  field  value   给key集合中的field赋值value

hget  key  field       获取key中field的值


hmset  key  field1 value1  field2 value2 .。。 设置多个值

hexists  key1 field  查看可key1中field的值是否存在


hkeys  key   列出该key集合中的所有field

hvals  key    列出该key集合中的所有value

hincrby   key  field   increment   为哈希表key中的field的值加上增量increment

hsetnx   key  field  value  将哈希表key中的field的值设置为value，当且仅当field不存在时








---------------------------------------------------
zset有序集合类型

redis的zset与set非常相似，是一个没有重复元素的字符串集合
不同在于zset中每个成员都关联了一个评分score，这个score被用来按照从低到高的方式排序集合中的成员
集合的成员是唯一的，但是score可以是重复的




zadd  key  score1 value1 score2 value2......   将一个或者多个元素及其score值加入到有序集key中

zrange  key  start stop  [withscores]      返回有序集key中，下标在start，stop之间的元素。 带有withscores时可以让分数一起和值返回

zrangebyscore  key  min max [withscores] [limit offset count]  返回有序集key中，所有score值介于min和max之间的成员（包括等于min和max的）。有序集成员按score值递增次序排列


zrevrangebyscore key  max min    [withscores] [limit offset count]  同上，改为从大到小

zincrby  key  increment  value     为元素的score加上增量

zrem  key  value    删除该集合下，指定值的元素

zcount  key  min  max    统计该集合，分数区间内的元素个数


zrank  key  value      返回该值在集合中的排名，从0开始



zset数据结构
1、类似于redis中hash类型的结构
2、跳跃表









-----------------------------------
redis配置文件

################################## INCLUDES ###################################部分
可以加载别的配置文件的配置

################################## NETWORK #####################################部分


bind 127.0.0.1  只支持本地连接，不能远程链接


tcp-backlog


timeout  当连接上之后，几秒内不操作就会断开链接。 默认0表示永不断开


################################# GENERAL #####################################部分

daemonize no



















-------------------------------------------------------------------------------

redis的发布与订阅

redis的发布订阅是一种消息通信模式，发送者(pub)发送消息，订阅者(sub)接收消息


redis客户端可以订阅任意数量的频道


命令行演示：
打开两个redis客户端，一个订阅频道mychannel1。 subscribe mychannel1。另一个在这个频道发送消息publish mychannel1 Hello。则第一个客户端可以收到这个信息。






-------------------------------------------------------------------------------
redis的新数据类型


bitmaps
Hyperloglog
geospatial



bitmaps
对位(bit)进行操作，位操作的字符串

setbit  key  偏移量  0/1
getbit key 偏移量

bitcount



-----

hyperloglog

pfadd 

pfcount 

pfmerge 

------

geospatial
对地图上经纬度的各种操作

经纬度设置，查询，距离查询等操作

geoadd

geopos

geodist


georadius







----------------------------------------------------------------------------

redis的事务

redis的事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序的执行。事务在执行的过程中，不会被其他客户端发来的命令所打断

redis的事务主要作用就是串联多个命令，防止别的命令插队



multi，开启组队(开启事务)
exec    开始执行
discard   取消组队，不执行


组队阶段，只要有一个错误，执行的时候都不会执行
执行阶段，有错误，则错误的这个不执行，其他的执行




悲观锁,每次操作数据都会上锁。
乐观锁，加了个版本号，操作这个key之前，这个key被其他命令改动了，版本号变了，则执行时判断版本号不一样，就不会执行

默认不能直接使用悲观锁



使用乐观锁：watch key...
在执行multi之前，先执行watch key1 key2 .. 可以监听一个或者多个key，如果事务执行之前这个key 被其他命令改动，则事务将被打断

unwatch 取消监听


redis事务的特性
1、单独的隔离操作 。  事务中的命令都会序列化，按顺序执行。在执行过程中，不会被其他客户端发送来的命令打断
2、没有隔离级别的概念 。  
3、不保证原子性 。  事务中如果有一个命令执行失败，其他命令仍会执行，没有回滚




商品秒杀案例: 例如有10个藏品，1000个人抢，出现高并发场景，可能导致商品库存变成负数。加乐观锁解决时，可能导致库存消耗不完(1000个人抢10个)，库存遗留问题。
用redis的lua脚本功能，脚本执行时不能被打断，可以解决。





-------------------------------------------------------------------
redis的持久化

两种持久化方式
1、RDB
2、AOF



1、RBD，在指定的时间间隔内将内存中的数据快照写入磁盘，也就是行话说的snapshot快照，恢复时是将快照文件直接读到内存

备份是怎样执行的：
redis会单独创建(fork)一个子进程来进行持久化。先将数据写入到一个临时文件，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
整个过程中，主进程是不进行任何io操作的。这就确保了极高的性能。如果需要大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更高效。
RDB方式的缺点是最后一次持久化后的数据可能丢失。(因为最后一次持久化，可能没到时间的话，服务器挂掉了，没有进行持久化)

(fork是复制一个与当前进程一模一样的进程。新进程的所有数据，变量，环境变量，数值等都与原进程一致，但是是一个全新的进程，并作为原来进程的子进程。消耗性能)

写时复制技术

.rdb文件


在redis.conf配置文件中dbfilename，默认为dump.rdb。dir参数表示存储目录。(在############# SNAPSHOTTING  #############下) 默认RDB是开启的

stop-writes-on-bgsave-error yes    当磁盘不能写时，是否不进行持久化
rdbcompression yes        
rdbchecksum yes    检查数据完整性
save。  例如：save 900 1  900秒内至少一个key发生变化，则持久化保存。  save 300 10 300秒内至少10给key变化，则保存。超过300时，会重新计算个数


当redis挂掉，重启时会自动加载持久化的文件，恢复数据到redis中




2、AOF

以日志的形式记录每个写操作(增量保存)，将redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件。redis启动之初会读取该文件重新构建数据。
换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。


在配置文件中，AOF默认不开启



appendfilename 默认是appendonly.aof 文件名

appendonly 默认是no。  改成yes为开启aof

aof与rbd在相同路径下生成

aof和rdb都开启的话，默认读取aof的数据


异常恢复
如遇到aof文件损坏，通过redis-check-aof 工具可以对其进行修复


aof同步频率设置

appendfsync everysec   每秒同步，每秒记入一次日志，如果宕机，本秒的数据可丢失。
appendfsync always   始终进行同步，每次写操作都会立刻记入日志。性能较差但是数据完整性较好
appendfsync no        redis不主动进行同步，把同步时机交给操作系统




rewrite压缩

aof采用文件追加方式，文件会越来越大，为了避免这种情况，新增了重写机制，
当aof文件的大小超过所设定的阈值时，redis就会启动aof文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令bgrewriteaof


重写原理，如何实现重写：
aof文件持续增大时，会fork出一条新进程来将文件重写(先写临时文件，在rename) redis4.0之后版本的重写，实质上就是把rdb的快照，以二进制的形式附在新的aof头部，
作为已有的历史数据，替换掉原来的流水账操作

触发机制，当触发时才会重写

no-appendfsync-on-rewrite no




总结aof持久化流程：
1、客户端的请求写命令会被追加到aof缓冲区内
2、aof缓冲区根据aof持久化策略(appendfsync always/everysec/no) 将操作sync同步到磁盘的aof文件中
3、aof文件大小过大，达到触发机制时或手动重写时，会对aof文件进行rewrite重写，压缩aof文件容量。
4、当redis服务重启时，会重新加载aof文件中的写操作进行数据恢复



aof优势：
备份机制更稳健，丢失数据概率更低

劣势：
比起rdb，占用更多磁盘空间。因为不仅存数据，还要存操作命令
恢复速度慢
每次读写都同步的话，有一定性能压力






用哪个好：
官方推荐两个都启用
如果对数据不敏感，可单独用rdb
不建议单独用aof，因为可能有bug
如果只是做纯内存缓存，可以两个都不用







------------------------------------------------
redis主从复制

主机数据更新后，根据配置和策略，自动同步到备机。master/slave机制，master以写为主，slave以读为主

1、读写分离。 减轻单台redis服务器的压力。 主服务器写，从服务器读操作

2、容灾的快速恢复。 一主多从的配置。当一台从服务器挂了，还可以从别的从服务器读取。


搭建主从复制

info replication.  查看当前redis是主还是从，主从复制的相关信息

例子：(一主两从)
1、在用户家目录创建目录 myredis，并进入目录
2、复制redis.conf配置文件 到目录。关闭aof功能。
3、配置一主两从，创建三个配置文件。redis6379.conf，redis6380.conf，redis6381.conf
4、在三个配置文件中写入内容  
include /myredis/redis.conf 
pidfile /var/run/redis_6379.pid/redis_6380.pid/redis_6381.pid
port 6379
dbfilename dump6379.rdb/dump6380.rdb/dump6381.rdb
5、启动三个redis服务。
使用info replication查看三个redis的主从信息。三个都为master
6、在6380，6381中执行 slaveof 127.0.0.1 6379，再使用info replication查看三个redis的主从信息.变为slave从机


在主机中添加数据时，会复制到从机中
从机中不能进行写操作。会报错

------------

一主二仆
当一个从服务器挂了时，然后重启后，又变成独立的主服务器了。
当一个从服务器挂了时，然后在主服务器中进行写入，把从服务器重启并执行slaveof到主服务器时，主服务器中刚才添加的数据也会在这个从服务器中存在(即主服务器的所有数据都会复制)。

当主服务器挂掉了，从服务器还是从服务器的状态，不做任何事情，然后用info replication查看时master_link_status:down，状态显示为down
然后当主服务器重启时，主服务器仍然是主服务器。从服务器还是之前的几个从服务器。



-----------

主从复制的原理：
1、从服务器连接上主服务器之后，从服务器会向主服务器发送一个进行数据同步的消息。
2、主服务器收到从服务器的消息之后，会把当前主服务器的数据进行持久化，放到rdn文件中，然后把rdb文件发送给从服务器。从服务器拿到rdb文件进行读取。(全量复制)

3、每次主服务器进行写操作之后，会和从服务器进行数据同步(这个动作是主服务器主动做的)。(增量复制)



-----------

薪火相传

主服务器只去同步一台从服务器，叫做a吧，这台从服务器再去同步其他的从服务器。
这时假如a服务器挂了，其他服务器就不能进行同步了。

上一个slave可以是下一个slave的master，slave同样可以接收来自其他slave的连接和请求。那么该slave作为了链条中的下一个master，可以有效减轻master的写压力。




-----------


反客为主

当主服务器挂了，其他从服务器可以晋升为主服务器。
使用命令   slaveof no one 将从机进行主机。手动完成的

哨兵模式是反客为主的自动版。可以自动进行晋升


-------------

哨兵模式

反客为主的自动版，能够后台监控主机是否发生故障，如果故障了根据投票数自动将从库转为主库


怎么使用：
例子：
1、先按上面步骤搭建一主二从。
2、在myredis目录中创建sentinel.conf文件，名字不能错
3、在sentinel.conf文件中写入  sentinel monitor mymaster 127.0.0.1 6379 1。mymaster是为监控对象起的服务器名称，1为至少有多少个哨兵同意迁移的数量。(例如只有两个从机，则1代表只要有1个从机同意切换就可以，2的话就是两个都同意才可切换)
4、启动哨兵。redis-sentinel  /myredis/sentinel.conf
5、shutdown主机。

此时，哨兵监控到主机挂了，从6380，6381选一个变为主服务器。例如6380变为主，6381变为6380的从机，6379重启后也是6380的从机

挑选出新的主服务器之后。sentinel向原主服务的从服务器发送slaveof 新主服务器的命令，复制新master
当已下线的服务重新上线后，sentinel会向其发送slaveof 命令，让其成为新主的从



复制延时
由于所有的写操作都是在master上操作，然后同步到slave上，所以从master同步到slave机器有一定的延迟，当系统很繁忙时，延迟问题会更严重。slave数量的增加也会使这个问题更严重



选择从服务器变为主服务器时，怎么选，选择条件依次为：(当1条件一样时，看第二个，然后看第三个)
1、选择优先级靠前的。    在redis的配置文件中，有一个slave-priority 100。  值越小优先级越高。   新版的好像改名了，是replica-priority
2、选择偏移量最大的。     偏移量是指获得原主机数据最全的。    info relication的master_repl_offset指标
3、选择runid最小的从服务       每个redis实例启动后都会随机生成一个40位的runid。 可通过命令info server查看








--------------------------------------------------------
redis集群

1、容量不够，redis怎么扩容？
用集群

2、并发写操作，redis如何分摊？
用集群


另外，主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址，端口等信息。很不方便
之前通过代理主机的方式解决，但是redis3.0中提供了解决方案，是无中心化集群配置


redis集群实现了对redis的水平扩容，即启动n个redis节点，将整个数据库分布存储在这n个节点中，每个节点存储总数据的1/n

redis集群通过分区来提供一定程度的可用性，即使集群中有一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求



---------------
搭建redis集群

1、制作六个实例。 6379，6380，6381，6389，6390，6391  (配置可按上面配置主从的配置来写就行).  然后删除之前的rdb文件
然后还要修改 cluster配置
cluster-enabled  yes  打开集群模式
cluster-config-file  nodes-6379.conf  设定节点配置文件
cluster-node-timeout  15000    设置节点失联时间，超过该时间(毫秒)，集群自动进行主从切换

2、 启动六个服务
3、将六个节点合成一个集群
组合之前，确保所有redis实例启动后，nodes-xxxx.conf文件都正常生成。

执行命令(进入redis安装文件src目录下执行)  (不知道为啥我在ubuntu上用apt安装的redis,找不到src目录)
redis-cli  --cluster  create --cluster-replicas 1 192.168.50.128:6379  192.168.50.128:6380  192.168.50.128:6381  192.168.50.128:6389 192.168.50.128:6390 192.168.50.128:6391

注意不要用127.0.0.1,用真实的ip

--cluster-replicas 1 表示以最简单的方式创建集群，一台主机，一台从机，正好三组


上面完成之后,可以进行连接看看
使用  redis-cli -c  -p  6379/6380/6381(三个中任意一个都可)    -c可以实现自动重定向
然后 使用 cluster nodes 命令可以查看集群信息




redis cluster是如何分配这六个节点的?
一个集群中至少三个主节点
选项--cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点
分配原则尽量保证每个主数据库运行在不同的ip地址,每个从库和对应的主库不在一个ip地址上.



什么是slots

插槽

一个redis集群包含16384个插槽(0-16383),数据库中的每个键都属于这16384个插槽中的一个.
集群使用公式:CRC16(key)%16384来计算key属于哪个槽.其中CRC16(key) 语句用于计算键key的CRC16校验和

集群中的每个节点负责处理一部分插槽.
举个列子:  假如有三个主节点.
a节点负责处理0-5460号插槽。
b节点负责处理5461-10922号插槽
c节点负责处理10923-16383号插槽


所以，当set k1 v1时，会计算属于哪个插槽，然后切换到该节点进行处理

当插入多个值时，mset key1 value1 key2 value2  此时会报错，不允许插入多个值. 不允许使用多键的操作
需要使用{}来定义组的概念，从而使key中{}内相同内容的键值对放到一个slot中.  例如:  mset name{user} luck age{user} 20


cluster keyslot  key  查看key的插槽值
cluster countkeysinslot   插槽值        查看该插槽值中键的数量(各个节点只能查看自己范围内的插槽值.例如:a节点只能查看0-5460号插槽中键的数量)
cluster getkeysinslot   插槽值  count        返回count个该插槽值中的键



故障恢复

如果主机下线,从机成为主机提供服务.  然后当之前挂掉的主机重新上线时,成为现在主机的从机.

如果某一段插槽的主从节点都宕掉,redis还能继续服务吗?
如果某一段插槽的主从节点都宕掉,而cluster-require-full-coverage 为 yes, 那么,整个集群都挂掉
如果某一段插槽的主从节点都宕掉,而cluster-require-full-coverage 为 no, 那么,该插槽数据全都不能使用,也无法存储

cluster-require-full-coverage 为配置文件中的参数







------------------------------------------------------------------------------------------------
redis 应用问题解决

缓存穿透
缓存击穿
缓存雪崩
分布式锁


-------------
缓存穿透

应用服务器压力突然变大了。来了很多请求，正常应该是先去查缓存。查不到再去数据库查。
然后redis中总是查不到，命中率降低了，然后导致一直去mysql数据库查，导致数据库压力急剧增加，最终崩溃
但是其实redis一直在平稳运行。只是redis没起到作用，一直在访问数据库，这个过程就是缓存穿透

可能遭受黑客攻击造成此问题。


key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。
比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。


一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，
如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。


解决：
（1）对空值缓存：如果一个查询返回的数据为空（不管是数据是否存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟

（2）设置可访问的名单（白名单）：
使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。

（3）采用布隆过滤器：(布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。
布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。)
将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。

（4）进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务

5、找网警。。。。。。(参考)




-----------------
缓存击穿

key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

数据库访问压力瞬时增大
redis没有出现大量key过期
redis正常运行

某个key过期，大量访问这个key。


key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。

解决问题：
（1）预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长
（2）实时调整：现场监控哪些数据热门，实时调整key的过期时长
（3）使用锁：
1、就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db。
2、先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key
3、当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key；
4、当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法。




-----------------
缓存雪崩


key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key


在极少的时间段查询大量key的集中过期情况

缓存失效时的雪崩效应对底层系统的冲击非常可怕！

解决方案：
（1）构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等）
（2）使用锁或队列：
用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况
（3）设置过期标志更新缓存：
记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。
（4）将缓存失效时间分散开：
比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。






-----------------
redis分布式锁


基于redis实现分布式锁：

使用SETNX加锁
用DEL来删除该锁

忘记释放锁时或者加锁的客户端在删除之前断开连接时(比如断电等)，就会一直等待。所以设置过期时间。

用原子操作set key value nx ex time  既上锁又设置过期时间。 防止上完锁断电了，来不及设置过期时间




使用lua脚本执行删除操作保证原子性。





































